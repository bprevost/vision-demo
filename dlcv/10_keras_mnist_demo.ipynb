{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by Deep Learning for Computer Vision with Python [Rosebrock]  \n",
    "Chapter 10  \n",
    "Keras: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MNIST dataset of 70,000 hand-written digits\n",
    "# 60,000 for training and 10,000 for testing\n",
    "((trainX, trainY), (testX, testY)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# flatten each 28x28x1 image to a simple list of 28x28=784 pixels\n",
    "trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))\n",
    "testX = testX.reshape((testX.shape[0], 28 * 28 * 1))\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype('float32') / 255.0\n",
    "testX = testX.astype('float32') / 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "num_features = trainX.shape[1]\n",
    "print(f'{num_features=}')\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(num_features,))) # input layer\n",
    "model.add(tf.keras.layers.Dense(256, activation='sigmoid')) # hidden layer\n",
    "model.add(tf.keras.layers.Dense(128, activation='sigmoid')) # hidden layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax')) # output layer\n",
    "model.summary()\n",
    "\n",
    "# initialize the gradient descent optimizer\n",
    "sgd = tf.keras.optimizers.SGD(0.01)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "EPOCHS = 100\n",
    "H = model.fit(x=trainX, y=trainY, validation_data=(testX, testY), epochs=EPOCHS, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "predictions = model.predict(testX, batch_size=128)\n",
    "label_names = [str(x) for x in lb.classes_]\n",
    "print(label_names)\n",
    "report = classification_report(\n",
    "    y_true=testY.argmax(axis=1),\n",
    "    y_pred=predictions.argmax(axis=1),\n",
    "    target_names=label_names)\n",
    "print(report)\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history['loss'], label='train_loss')\n",
    "plt.plot(np.arange(0, EPOCHS), H.history['val_loss'], label='val_loss')\n",
    "plt.plot(np.arange(0, EPOCHS), H.history['accuracy'], label='train_acc')\n",
    "plt.plot(np.arange(0, EPOCHS), H.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
