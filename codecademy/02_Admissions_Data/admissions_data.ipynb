{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admissions Data\n",
    "\n",
    "Codacademy Exercise: Deep Learning Regression\n",
    "\n",
    "Predict graduate school admission probability using a neural network to perform regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset into a pandas DataFrame\n",
    "dataset = pd.read_csv('admissions_data.csv')\n",
    "\n",
    "# print the first five entries in the dataset and the summary stats\n",
    "print(dataset.head(5))\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the serial number column from the dataset\n",
    "dataset = dataset.drop(['Serial No.'], axis=1)\n",
    "\n",
    "# split the data into labels and features\n",
    "labels = dataset.iloc[:, -1] # select the last column\n",
    "features = dataset.iloc[:, 0:-1] # select all columns except the last\n",
    "\n",
    "# split the data into a training set and a test set\n",
    "features_train, features_test, labels_train_set, labels_test_set = train_test_split(features, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "# standardize the numerical features\n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns\n",
    "ct = ColumnTransformer([('numeric', StandardScaler(), numerical_columns)], remainder='passthrough')\n",
    "features_train_scale = ct.fit_transform(features_train)\n",
    "features_test_scale = ct.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "num_features = features.shape[1]\n",
    "my_model = Sequential()\n",
    "my_model.add(InputLayer(input_shape=(num_features,)))\n",
    "my_model.add(Dense(16, activation = 'relu')) # hidden layer\n",
    "my_model.add(Dropout(0.1))\n",
    "my_model.add(Dense(8, activation = 'relu')) # hidden layer\n",
    "my_model.add(Dropout(0.2))\n",
    "my_model.add(Dense(1)) # output layer\n",
    "print(my_model.summary())\n",
    "\n",
    "# initialize the gradient descent optimizer\n",
    "opt = Adam(learning_rate=0.005)\n",
    "\n",
    "# compile the model\n",
    "# using mean-squared error as the loss function and mean average error as the metric\n",
    "my_model.compile(loss = 'mse', metrics = ['mae'], optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20) # early stopping\n",
    "history = my_model.fit(features_train_scale, labels_train_set, epochs=100, batch_size=8, verbose=1, validation_split=0.25, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the trained model with the test set\n",
    "val_mse, val_mae = my_model.evaluate(features_test_scale, labels_test_set, verbose=1)\n",
    "print('MAE: ', val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history['mae'])\n",
    "ax1.plot(history.history['val_mae'])\n",
    "ax1.set_title('model mae')\n",
    "ax1.set_ylabel('MAE')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# Plot loss and val_loss over each epoch\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('model loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# used to keep plots from overlapping each other\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOqWNHKIzbHurbcgxT52TiX",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
