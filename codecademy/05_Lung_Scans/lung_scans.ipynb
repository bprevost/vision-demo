{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Scans\n",
    "\n",
    "Codacademy Exercise: Deep Learning Classification\n",
    "\n",
    "Diagnose pneumonia, covid-19, or no illness, based on a patient's x-ray scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training images and preprocess with augmentation\n",
    "print('Loading training data...')\n",
    "training_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1.0/255,         # pixel normalization\n",
    "    zoom_range=0.1,          # randomly increase or decrease the size of the image by up to 10%\n",
    "    rotation_range=25,       # randomly rotate the image between -25,25 degrees\n",
    "    height_shift_range=0.05, # Shift the image along its height by up to +/- 5%\n",
    "    width_shift_range=0.05,  # Shift the image along its width by up to +/- 5%\n",
    ")\n",
    "print(training_data_generator.__dict__)\n",
    "training_iterator = training_data_generator.flow_from_directory(\n",
    "    directory='dataset/train',\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "sample_batch_input, sample_batch_labels = training_iterator.next()\n",
    "print(sample_batch_input.shape, sample_batch_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load validation data without augmentation\n",
    "print('Loading validation data...')\n",
    "validation_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1.0/255, # pixel normalization\n",
    ")\n",
    "print(validation_data_generator.__dict__)\n",
    "validation_iterator =  validation_data_generator.flow_from_directory(\n",
    "    directory='dataset/test',\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "sample_batch_input, sample_batch_labels = training_iterator.next()\n",
    "print(sample_batch_input.shape, sample_batch_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "print('Building the model...')\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(256, 256, 1))) # input layer\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=5, kernel_size=5, strides=3, padding='valid', activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=3, kernel_size=3, strides=1, padding='valid', activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(8, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "print('Compiling the model...')\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.AUC(name='auc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "print('Training the model...')\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_auc', mode='min', verbose=1, patience=20)\n",
    "history = model.fit(\n",
    "    training_iterator,\n",
    "    steps_per_epoch=training_iterator.samples/BATCH_SIZE,\n",
    "    epochs=50,\n",
    "    validation_data=validation_iterator,\n",
    "    validation_steps=validation_iterator.samples/BATCH_SIZE,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)\n",
    "print(history.params)\n",
    "print(history.history.keys())\n",
    "\n",
    "# plotting categorical and validation accuracy over epochs\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history['categorical_accuracy'])\n",
    "ax1.plot(history.history['val_categorical_accuracy'])\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# plotting auc and validation auc over epochs\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history['auc'])\n",
    "ax2.plot(history.history['val_auc'])\n",
    "ax2.set_title('model auc')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('auc')\n",
    "ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# classification report\n",
    "test_steps_per_epoch = math.ceil(validation_iterator.samples / validation_iterator.batch_size)\n",
    "predictions = model.predict(validation_iterator, steps=test_steps_per_epoch)\n",
    "test_steps_per_epoch = math.ceil(validation_iterator.samples / validation_iterator.batch_size)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = validation_iterator.classes\n",
    "class_labels = list(validation_iterator.class_indices.keys())\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)\n",
    "\n",
    "# confusion matrix\n",
    "cm=confusion_matrix(true_classes, predicted_classes)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
